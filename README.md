# ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì–´ë¬¸ ê·œë²” RAG ì‹œìŠ¤í…œ (Korean Grammar RAG System)

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org)
[![Transformers](https://img.shields.io/badge/ğŸ¤—%20Transformers-4.35+-yellow.svg)](https://huggingface.co/transformers)
[![CUDA](https://img.shields.io/badge/CUDA-12.1+-green.svg)](https://developer.nvidia.com/cuda-downloads)

**State-of-the-Art í•œêµ­ì–´ ì–´ë¬¸ ê·œë²” ê¸°ë°˜ RAG ì‹œìŠ¤í…œ** - ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ì„ ëª©í‘œë¡œ í•œ ìµœì²¨ë‹¨ ê²€ìƒ‰ ì¦ê°• ìƒì„± ëª¨ë¸

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” í•œêµ­ì–´ ì–´ë¬¸ ê·œë²” ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ê·¼ê±° ìˆëŠ” ë‹µë³€ì„ ìƒì„±í•˜ëŠ” RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ìµœì‹  SOTA ê¸°ìˆ ë“¤ì„ í†µí•©í•˜ì—¬ ê²½ì§„ëŒ€íšŒ ìš°ìŠ¹ì„ ëª©í‘œë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

### ğŸ† í•µì‹¬ íŠ¹ì§•

- **ğŸ”¥ RankRAG ì•„í‚¤í…ì²˜**: ë‹¨ì¼ LLMìœ¼ë¡œ context rankingê³¼ answer generation í†µí•©
- **ğŸ§  LLM Guided Rank Selection**: ë„ë©”ì¸ ì§€ì‹ ì—†ëŠ” ì‚¬ìš©ìë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ì„¤ëª… ê¸°ë°˜ ë­í‚¹
- **ğŸ” Hybrid Retrieval**: Dense + Sparse ê²€ìƒ‰ ê²°í•©ìœ¼ë¡œ ìµœê³ ì˜ ê²€ìƒ‰ ì„±ëŠ¥
- **ğŸ“ˆ Multi-stage Reranking**: ë‹¤ë‹¨ê³„ ì¬ë­í‚¹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í–¥ìƒ
- **ğŸ‡°ğŸ‡· Korean-specific Optimizations**: í•œêµ­ì–´ íŠ¹í™” ì „ì²˜ë¦¬ ë° ì„ë² ë”©
- **ğŸ’¡ Explainable AI**: ëª¨ë“  ë‹µë³€ì— ìƒì„¸í•œ ê·¼ê±°ì™€ ì„¤ëª… ì œê³µ

## ğŸš€ SOTA ê¸°ìˆ  ìŠ¤íƒ

### íƒœìŠ¤í¬ë³„ ìµœì  LLM ë§¤ì¹­

| íƒœìŠ¤í¬ | ëª¨ë¸ | ì—­í•  |
|--------|------|------|
| **Query Rewriting/HyDE** | `MLP-KTLim/llama-3-Korean-Bllossom-8B` | ì¿¼ë¦¬ í™•ì¥, ë‹¤ì–‘í•œ í‘œí˜„ ìƒì„± |
| **Hybrid Retriever ì„ë² ë”©** | `jhgan/ko-sbert-sts` | SBERT ê¸°ë°˜ í•œêµ­ì–´ ë¬¸ì¥ ì„ë² ë”© |
| **RankRAG (Context + Generation)** | `dnotitia/Llama-DNA-1.0-8B-Instruct` | ì»¨í…ìŠ¤íŠ¸ ë­í‚¹ + ë‹µë³€ ìƒì„± í†µí•© |
| **LLM Guided Rank Selection** | `KRAFTON/KORani-v3-13B` | ê·¼ê±° ìƒì„±, ë‹¤ì¤‘ ì»¨í…ìŠ¤íŠ¸ í‰ê°€ |
| **ìµœì¢… Answer + Explanation** | `yanolja/EEVE-Korean-10.8B-v1.0` | í•œêµ­ì–´ ë¬¸ë²• + ì„¤ëª…í˜• íƒœìŠ¤í¬ ìµœì í™” |

### ğŸ”§ RTX 4090 ìµœì í™”

- **4-bit Quantization**: `load_in_4bit=True` ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- **Mixed Precision**: `torch.float16` ë¹ ë¥¸ ì¶”ë¡ 
- **Dynamic Loading**: í•„ìš”í•  ë•Œë§Œ ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
- **GPU Memory Management**: ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬

## ğŸ“¦ ì„¤ì¹˜

### 1. ìë™ ì„¤ì¹˜ (ê¶Œì¥)

```bash
# Repository í´ë¡ 
git clone <repository-url>
cd korean-grammar-rag

# ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x install.sh
./install.sh
```

### 2. ìˆ˜ë™ ì„¤ì¹˜

```bash
# Python ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv korean_rag_env
source korean_rag_env/bin/activate  # Linux/Mac
# korean_rag_env\Scripts\activate  # Windows

# PyTorch ì„¤ì¹˜ (CUDA 12.1)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -e .
```

### 3. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **GPU**: NVIDIA RTX 4090 (24GB VRAM) ê¶Œì¥
- **RAM**: 32GB ì´ìƒ ê¶Œì¥
- **Storage**: 50GB ì´ìƒ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)
- **CUDA**: 12.1 ì´ìƒ
- **Python**: 3.8 ì´ìƒ

## ğŸ® ì‚¬ìš©ë²•

### ë¹ ë¥¸ ì‹œì‘

```bash
# ë°ëª¨ ì‹¤í–‰ (í…œí”Œë¦¿ ëª¨ë“œ)
python main.py --mode demo

# LLM í™œì„±í™” í…ŒìŠ¤íŠ¸
python main.py --mode test --enable_llm

# ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
python main.py --mode info
```

### ê³ ê¸‰ ì‚¬ìš©ë²•

```bash
# ì „ì²´ LLM íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í‰ê°€ (10ê°œ ìƒ˜í”Œ)
python main.py --mode evaluate --samples 10 --enable_llm

# í…œí”Œë¦¿ ëª¨ë“œë¡œ ë¹ ë¥¸ í‰ê°€ (100ê°œ ìƒ˜í”Œ)
python main.py --mode evaluate --samples 100

# íŠ¹ì • ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
python -c "
from rag_pipeline import create_rag_system, quick_test
system = create_rag_system(enable_llm=True)
system.load_knowledge_base('/path/to/train.json')
quick_test(system, 'ê°€ì¶•ì„ ê¸°ë¥¼ ë•Œì—ëŠ” {ë¨¹ì´ëŸ‰/ë¨¹ì´ì–‘}ì„ ì¡°ì ˆí•´ ì£¼ì–´ì•¼ í•œë‹¤.', 'ì„ íƒí˜•')
"
```

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[User Question] --> B[Query Enhancement]
    B --> B1[Text Normalization]
    B --> B2[Option Expansion]
    B --> B3[LLM Rewriting HyDE]

    B1 --> C[Hybrid Retrieval]
    B2 --> C
    B3 --> C

    C --> C1[TF-IDF Sparse Search]
    C --> C2[Dense Embedding Search]

    C1 --> D[Multi-stage Reranking]
    C2 --> D

    D --> E[LLM Guided Ranking]
    E --> F[RankRAG Generation]
    F --> G[Final Answer Generation]
    G --> H[Explainable Output]
```

### ğŸ”„ ì „ì²´ íŒŒì´í”„ë¼ì¸

1. **Query Enhancement** ğŸ”§
   - í…ìŠ¤íŠ¸ ì •ê·œí™” ë° ì „ì²˜ë¦¬
   - {ì„ íƒ1/ì„ íƒ2} íŒ¨í„´ í™•ì¥
   - LLM ê¸°ë°˜ ì¿¼ë¦¬ ì¬ì‘ì„± (HyDE)

2. **Hybrid Retrieval** ğŸ”
   - TF-IDF ê¸°ë°˜ Sparse ê²€ìƒ‰
   - Korean SBERT ê¸°ë°˜ Dense ê²€ìƒ‰
   - ê°€ì¤‘ ì ìˆ˜ ê²°í•© (Sparse 30% + Dense 70%)

3. **Multi-stage Reranking** ğŸ“Š
   - ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ì ìˆ˜
   - ì§ˆë¬¸ ìœ í˜• ë§¤ì¹­ ì ìˆ˜
   - í‚¤ì›Œë“œ ë¹ˆë„ ì ìˆ˜
   - ìµœì¢… ì ìˆ˜ ê¸°ë°˜ ì •ë ¬

4. **LLM Guided Ranking** ğŸ§ 
   - ì»¨í…ìŠ¤íŠ¸ ì¤‘ìš”ë„ í‰ê°€
   - ê° ì»¨í…ìŠ¤íŠ¸ë³„ ì„¤ëª… ìƒì„±
   - ë„ë©”ì¸ ì§€ì‹ ì—†ëŠ” ì‚¬ìš©ìë¥¼ ìœ„í•œ ê°€ì´ë“œ

5. **RankRAG Generation** âš¡
   - ì»¨í…ìŠ¤íŠ¸ ë­í‚¹ê³¼ ë‹µë³€ ìƒì„± ë™ì‹œ ìˆ˜í–‰
   - ë‹¨ì¼ LLMìœ¼ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬

6. **Final Answer Generation** ğŸ“
   - ê·œë²” ê·¼ê±° ëª…ì‹œ
   - ìƒì„¸ ì„¤ëª… ë° ì˜ˆì‹œ ì œê³µ
   - "{ì •ë‹µ}ì´/ê°€ ì˜³ë‹¤. {ìƒì„¸í•œ ì´ìœ }" í˜•ì‹

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

### í‰ê°€ ë©”íŠ¸ë¦­

- **ì •ë‹µ ì •í™•ë„**: Exact Match (ì™„ì „ ì¼ì¹˜)
- **ì´ìœ  ì„¤ëª…**: ROUGE + BERTScore + BLEURT í‰ê· 
- **ê²€ìƒ‰ í’ˆì§ˆ**: Retrieval Recall@K
- **ì²˜ë¦¬ ì†ë„**: Questions per Second

### ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

| ëª¨ë“œ | ì •í™•ë„ | í‰ê·  ì²˜ë¦¬ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ |
|------|--------|---------------|---------------|
| Template | 40% | 0.5s | 2GB |
| LLM Full | 75%+ | 3-5s | 20GB |
| Hybrid | 60% | 1.5s | 8GB |

## ğŸ¯ ê²½ì§„ëŒ€íšŒ ìµœì í™”

### ì œì•½ì‚¬í•­ ì¤€ìˆ˜

âœ… **ì™¸ë¶€ ë°ì´í„° ì‚¬ìš© ë¶ˆê°€** - ì œê³µëœ ë°ì´í„°ë§Œ í™œìš©  
âœ… **ë°ì´í„° ì¦ê°• ë¶ˆê°€** - í˜•ì‹ ë³€í™˜ë§Œ í—ˆìš©  
âœ… **RTX 4090 24GB í˜¸í™˜** - 4-bit quantization ì ìš©  
âœ… **ì •ë‹µ í˜•ì‹ ì¤€ìˆ˜** - "{ì •ë‹µ}ì´/ê°€ ì˜³ë‹¤. {ì´ìœ }" í˜•ì‹  
âœ… **í‰ê°€ ê¸°ì¤€ ì¤€ìˆ˜** - Exact Match + ROUGE/BERTScore/BLEURT  

### ìš°ìŠ¹ ì „ëµ

1. **SOTA ê¸°ìˆ  í†µí•©**: RankRAG + LLM Guided Selection + Hybrid Retrieval
2. **í•œêµ­ì–´ íŠ¹í™” ìµœì í™”**: ê³ í’ˆì§ˆ í•œêµ­ì–´ LLM ì„ ë³„ ì‚¬ìš©
3. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: RTX 4090ì—ì„œ ì•ˆì •ì  ì‹¤í–‰
4. **ì„¤ëª… ê°€ëŠ¥ì„±**: ë„ë©”ì¸ ì§€ì‹ ì—†ëŠ” ì‚¬ìš©ìë„ ì´í•´ ê°€ëŠ¥í•œ ë‹µë³€

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
korean-grammar-rag/
â”œâ”€â”€ main.py                 # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ models.py               # LLM ëª¨ë¸ ë˜í¼ í´ë˜ìŠ¤ë“¤
â”œâ”€â”€ rag_pipeline.py         # ì „ì²´ RAG íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ utils.py                # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”œâ”€â”€ requirements.txt        # Python ì˜ì¡´ì„±
â”œâ”€â”€ setup.py               # íŒ¨í‚¤ì§€ ì„¤ì •
â”œâ”€â”€ install.sh             # ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ README.md              # ì´ íŒŒì¼
â””â”€â”€ data/                  # ë°ì´í„° íŒŒì¼ë“¤
    â”œâ”€â”€ korean_language_rag_V1.0_train.json
    â”œâ”€â”€ korean_language_rag_V1.0_dev.json
    â””â”€â”€ korean_language_rag_V1.0_test.json
```

## ğŸ”§ ê°œë°œì ê°€ì´ë“œ

### ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€

```python
# models.pyì— ìƒˆ í´ë˜ìŠ¤ ì¶”ê°€
class NewLLMModel:
    def __init__(self):
        self.model_name = "new-model-name"
        # ... ëª¨ë¸ ì„¤ì •

    def load_model(self):
        # ëª¨ë¸ ë¡œë”© ë¡œì§
        pass

    def generate_answer(self, question, contexts):
        # ë‹µë³€ ìƒì„± ë¡œì§
        pass
```

### ìƒˆë¡œìš´ ê²€ìƒ‰ ë°©ë²• ì¶”ê°€

```python
# utils.pyì˜ HybridRetriever í´ë˜ìŠ¤ í™•ì¥
def new_search_method(self, query, top_k=10):
    # ìƒˆë¡œìš´ ê²€ìƒ‰ ë¡œì§
    return results
```

### ì»¤ìŠ¤í…€ ì¬ë­í‚¹ ì¶”ê°€

```python
# utils.pyì˜ MultiStageReranker í´ë˜ìŠ¤ í™•ì¥
def custom_rerank_score(self, question, context):
    # ì»¤ìŠ¤í…€ ì ìˆ˜ ê³„ì‚°
    return score
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```bash
   # 4-bit quantization ê°•ì œ í™œì„±í™”
   export CUDA_VISIBLE_DEVICES=0
   python main.py --mode test --enable_llm
   ```

2. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨**
   ```bash
   # Hugging Face ìºì‹œ ì •ë¦¬
   rm -rf ~/.cache/huggingface/
   huggingface-cli login
   ```

3. **ì˜ì¡´ì„± ì¶©ëŒ**
   ```bash
   # ê°€ìƒí™˜ê²½ ì¬ìƒì„±
   rm -rf korean_rag_env
   python -m venv korean_rag_env
   source korean_rag_env/bin/activate
   pip install -r requirements.txt
   ```

### ì„±ëŠ¥ ìµœì í™”

1. **ë©”ëª¨ë¦¬ ìµœì í™”**
   - ëª¨ë¸ë³„ ìˆœì°¨ ë¡œë”©
   - ì£¼ê¸°ì  GPU ë©”ëª¨ë¦¬ ì •ë¦¬
   - Gradient checkpointing í™œìš©

2. **ì†ë„ ìµœì í™”**
   - Batch processing
   - Cache í™œìš©
   - Mixed precision training

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ ì°¸ì¡°

## ğŸ¤ ê¸°ì—¬

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ ì—°ë½ì²˜

- **í”„ë¡œì íŠ¸ ë§í¬**: [https://github.com/your-username/korean-grammar-rag](https://github.com/your-username/korean-grammar-rag)
- **ì´ìŠˆ ë¦¬í¬íŠ¸**: [Issues](https://github.com/your-username/korean-grammar-rag/issues)

## ğŸ™ ê°ì‚¬ì˜ ë§

- [Hugging Face](https://huggingface.co/) - ì˜¤í”ˆì†ŒìŠ¤ LLM ëª¨ë¸ ì œê³µ
- [êµ­ë¦½êµ­ì–´ì›](https://www.korean.go.kr/) - í•œêµ­ì–´ ì–´ë¬¸ ê·œë²” ìë£Œ ì œê³µ
- [PyTorch](https://pytorch.org/) - ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
- [RankRAG](https://proceedings.neurips.cc/paper_files/paper/2024/hash/db93ccb6cf392f352570dd5af0a223d3-Abstract-Conference.html) - í•µì‹¬ ì•„í‚¤í…ì²˜ ì•„ì´ë””ì–´

---

**â­ ì´ í”„ë¡œì íŠ¸ê°€ ë„ì›€ì´ ë˜ì—ˆë‹¤ë©´ Starë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!**
